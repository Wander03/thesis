
@article{agrawal_mining_1993,
	title = {Mining association rules between sets of items in large databases},
	volume = {22},
	issn = {0163-5808},
	url = {https://doi.org/10.1145/170036.170072},
	doi = {10.1145/170036.170072},
	abstract = {We are given a large database of customer transactions. Each transaction consists of items purchased by a customer in a visit. We present an efficient algorithm that generates all significant association rules between items in the database. The algorithm incorporates buffer management and novel estimation and pruning techniques. We also present results of applying this algorithm to sales data obtained from a large retailing company, which shows the effectiveness of the algorithm.},
	number = {2},
	journal = {SIGMOD Rec.},
	author = {Agrawal, Rakesh and Imieli≈Ñski, Tomasz and Swami, Arun},
	month = jun,
	year = {1993},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {207--216},
	file = {PDF:C\:\\Users\\adker\\Zotero\\storage\\99ZNN96B\\Agrawal et al. - 1993 - Mining association rules between sets of items in large databases.pdf:application/pdf},
}

@article{zaki_scalable_2000,
	title = {Scalable algorithms for association mining},
	volume = {12},
	doi = {10.1109/69.846291},
	abstract = {Association rule discovery has emerged as an important problem in knowledge discovery and data mining. The association mining task consists of identifying the frequent itemsets, and then forming conditional implication rules among them. We present efficient algorithms for the discovery of frequent itemsets which forms the compute intensive phase of the task. The algorithms utilize the structural properties of frequent itemsets to facilitate fast discovery. The items are organized into a subset lattice search space, which is decomposed into small independent chunks or sublattices, which can be solved in memory. Efficient lattice traversal techniques are presented which quickly identify all the long frequent itemsets and their subsets if required. We also present the effect of using different database layout schemes combined with the proposed decomposition and traversal techniques. We experimentally compare the new algorithms against the previous approaches, obtaining improvements of more than an order of magnitude for our test databases.},
	number = {3},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zaki, M.J.},
	year = {2000},
	keywords = {Books, Costs, Data mining, Itemsets, Lattices, Marketing and sales, Space technology, Spatial databases, Testing},
	pages = {372--390},
	file = {eclat.pdf:C\:\\Users\\adker\\Zotero\\storage\\4FNZJWXP\\eclat.pdf:application/pdf},
}

@misc{hvitfeldt_tidyclust_2022,
	title = {tidyclust: {A} {Common} {API} to {Clustering}},
	shorttitle = {tidyclust},
	url = {https://CRAN.R-project.org/package=tidyclust},
	doi = {10.32614/CRAN.package.tidyclust},
	abstract = {A common interface to specifying clustering models, in the same style as 'parsnip'. Creates unified interface across different functions and computational engines.},
	language = {en},
	urldate = {2025-04-07},
	author = {Hvitfeldt, Emil and Bodwin, Kelly},
	month = nov,
	year = {2022},
	note = {Institution: Comprehensive R Archive Network
Pages: 0.2.4},
	keywords = {R package},
	file = {PDF:C\:\\Users\\adker\\Zotero\\storage\\I2JZ7IVC\\Hvitfeldt and Bodwin - 2022 - tidyclust A Common API to Clustering.pdf:application/pdf},
}

@book{kuhn_tidymodels_2020,
	title = {Tidymodels: a collection of packages for modeling and machine learning using tidyverse principles.},
	url = {https://www.tidymodels.org},
	author = {Kuhn, Max and Wickham, Hadley},
	year = {2020},
	keywords = {R package},
}

@article{hahsler_arules_2011,
	title = {The arules {R}-{Package} {Ecosystem}: {Analyzing} {Interesting} {Patterns} from {Large} {Transaction} {Datasets}},
	volume = {12},
	url = {https://jmlr.csail.mit.edu/papers/v12/hahsler11a.html},
	journal = {Journal of Machine Learning Research},
	author = {Hahsler, Michael and Chelluboina, Sudheer and Hornik, Kurt and Buchta, Christian},
	year = {2011},
	keywords = {R package},
	pages = {1977--1981},
	file = {Full Text PDF:C\:\\Users\\adker\\Zotero\\storage\\RF2EHWS7\\Hahsler et al. - 2011 - The arules R-Package Ecosystem Analyzing Interesting Patterns from Large Transaction Datasets.pdf:application/pdf},
}

@inproceedings{cheng_discriminative_2007,
	title = {Discriminative {Frequent} {Pattern} {Analysis} for {Effective} {Classification}},
	doi = {10.1109/ICDE.2007.367917},
	booktitle = {2007 {IEEE} 23rd {International} {Conference} on {Data} {Engineering}},
	author = {Cheng, Hong and Yan, Xifeng and Han, Jiawei and Hsu, Chih-Wei},
	year = {2007},
	keywords = {Data mining, Association rules, Frequency measurement, Gain measurement, Indexing, Kernel, Pattern analysis, Scalability, Solids, Text categorization},
	pages = {716--725},
}

@article{wickramaratna_predicting_2009,
	title = {Predicting {Missing} {Items} in {Shopping} {Carts}},
	volume = {21},
	doi = {10.1109/TKDE.2008.229},
	number = {7},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wickramaratna, Kasun and Kubat, Miroslav and Premaratne, Kamal},
	year = {2009},
	keywords = {Data mining, Itemsets, Testing, Bayesian methods, Counting circuits, Dairy products, Dempster-Shafer theory, Dempster-Shafer theory., Diseases, frequent itemsets, Frequent itemsets, Medical tests, Tree data structures, Uncertainty, uncertainty processing},
	pages = {985--998},
}

@inproceedings{mobasher_effective_2001,
	address = {New York, NY, USA},
	series = {{WIDM} '01},
	title = {Effective personalization based on association rule discovery from web usage data},
	isbn = {1-58113-444-4},
	url = {https://doi.org/10.1145/502932.502935},
	doi = {10.1145/502932.502935},
	abstract = {To engage visitors to a Web site at a very early stage (i.e., before registration or authentication), personalization tools must rely primarily on clickstream data captured in Web server logs. The lack of explicit user ratings as well as the sparse nature and the large volume of data in such a setting poses serious challenges to standard collaborative filtering techniques in terms of scalability and performance. Web usage mining techniques such as clustering that rely on offline pattern discovery from user transactions can be used to improve the scalability of collaborative filtering, however, this is often at the cost of reduced recommendation accuracy. In this paper we propose effective and scalable techniques for Web personalization based on association rule discovery from usage data. Through detailed experimental evaluation on real usage data, we show that the proposed methodology can achieve better recommendation effectiveness, while maintaining a computational advantage over direct approaches to collaborative filtering such as the k-nearest-neighbor strategy.},
	booktitle = {Proceedings of the 3rd {International} {Workshop} on {Web} {Information} and {Data} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Mobasher, Bamshad and Dai, Honghua and Luo, Tao and Nakagawa, Miki},
	year = {2001},
	note = {event-place: Atlanta, Georgia, USA},
	keywords = {association rules, collaborative filtering, personalization, web usage mining},
	pages = {9--15},
}

@inproceedings{liu_integrating_1998,
	address = {New York, NY},
	series = {{KDD}'98},
	title = {Integrating classification and association rule mining},
	abstract = {Classification rule mining aims to discover a small set of rules in the database that forms an accurate classifier. Association rule mining finds all the rules existing in the database that satisfy some minimum support and minimum confidence constraints. For association rule mining, the target of discovery is not pre-determined, while for classification rule mining there is one and only one predetermined target. In this paper, we propose to integrate these two mining techniques. The integration is done by focusing on mining a special subset of association rules, called class association rules (CARs). An efficient algorithm is also given for building a classifier based on the set of discovered CARs. Experimental results show that the classifier built this way is, in general, more accurate than that produced by the state-of-the-art classification system C4.5. In addition, this integration helps to solve a number of problems that exist in the current classification systems.},
	booktitle = {Proceedings of the {Fourth} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {AAAI Press},
	author = {Liu, Bing and Hsu, Wynne and Ma, Yiming},
	year = {1998},
	pages = {80--86},
}

@article{han_frequent_2007,
	title = {Frequent pattern mining: current status and future directions},
	volume = {15},
	issn = {1384-5810},
	url = {https://doi.org/10.1007/s10618-006-0059-1},
	doi = {10.1007/s10618-006-0059-1},
	abstract = {Frequent pattern mining has been a focused theme in data mining research for over a decade. Abundant literature has been dedicated to this research and tremendous progress has been made, ranging from efficient and scalable algorithms for frequent itemset mining in transaction databases to numerous research frontiers, such as sequential pattern mining, structured pattern mining, correlation mining, associative classification, and frequent pattern-based clustering, as well as their broad applications. In this article, we provide a brief overview of the current status of frequent pattern mining and discuss a few promising research directions. We believe that frequent pattern mining research has substantially broadened the scope of data analysis and will have deep impact on data mining methodologies and applications in the long run. However, there are still some challenging research issues that need to be solved before frequent pattern mining can claim a cornerstone approach in data mining applications.},
	number = {1},
	journal = {Data Min. Knowl. Discov.},
	author = {Han, Jiawei and Cheng, Hong and Xin, Dong and Yan, Xifeng},
	month = aug,
	year = {2007},
	note = {Place: USA
Publisher: Kluwer Academic Publishers},
	keywords = {Association rules, Applications, Data mining research, Frequent pattern mining},
	pages = {55--86},
}

@article{raschka_mlxtend_2018,
	title = {{MLxtend}: {Providing} machine learning and data science utilities and extensions to {Python}‚Äôs scientific computing stack},
	volume = {3},
	url = {https://joss.theoj.org/papers/10.21105/joss.00638},
	doi = {10.21105/joss.00638},
	number = {24},
	journal = {The Journal of Open Source Software},
	author = {Raschka, Sebastian},
	month = apr,
	year = {2018},
	note = {Publisher: The Open Journal},
	file = {Full Text PDF:C\:\\Users\\adker\\Zotero\\storage\\R5RD5NW6\\Raschka - 2018 - MLxtend Providing machine learning and data science utilities and extensions to Python‚Äôs scientific.pdf:application/pdf},
}

@article{han_mining_2000,
	title = {Mining frequent patterns without candidate generation},
	volume = {29},
	issn = {0163-5808},
	url = {https://doi.org/10.1145/335191.335372},
	doi = {10.1145/335191.335372},
	abstract = {Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist prolific patterns and/or long patterns.In this study, we propose a novel frequent pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a highly condensed, much smaller data structure, which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts a pattern fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent pattern mining methods.},
	number = {2},
	journal = {SIGMOD Rec.},
	author = {Han, Jiawei and Pei, Jian and Yin, Yiwen},
	month = may,
	year = {2000},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {1--12},
	file = {Full Text PDF:C\:\\Users\\adker\\Zotero\\storage\\UPUANVZK\\Han et al. - 2000 - Mining frequent patterns without candidate generation.pdf:application/pdf},
}

@inproceedings{buitinck_api_2013,
	title = {{API} design for machine learning software: experiences from the scikit-learn project},
	booktitle = {{ECML} {PKDD} {Workshop}: {Languages} for {Data} {Mining} and {Machine} {Learning}},
	author = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and VanderPlas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Ga√´l},
	year = {2013},
	pages = {108--122},
}

@article{wickham_welcome_2019,
	title = {Welcome to the tidyverse},
	volume = {4},
	doi = {10.21105/joss.01686},
	number = {43},
	journal = {Journal of Open Source Software},
	author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran√ßois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M√ºller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
	year = {2019},
	pages = {1686},
}

@book{kuhn_parsnip_2024,
	title = {parsnip: {A} {Common} {API} to {Modeling} and {Analysis} {Functions}},
	url = {https://CRAN.R-project.org/package=parsnip},
	author = {Kuhn, Max and Vaughan, Davis},
	year = {2024},
}

@book{kuhn_recipes_2024,
	title = {recipes: {Preprocessing} and {Feature} {Engineering} {Steps} for {Modeling}},
	url = {https://CRAN.R-project.org/package=recipes},
	author = {Kuhn, Max and Wickham, Hadley and Hvitfeldt, Emil},
	year = {2024},
}

@book{vaughan_workflows_2024,
	title = {workflows: {Modeling} {Workflows}},
	url = {https://CRAN.R-project.org/package=workflows},
	author = {Vaughan, Davis and Couch, Simon},
	year = {2024},
}

@book{kuhn_tune_2024,
	title = {tune: {Tidy} {Tuning} {Tools}},
	url = {https://CRAN.R-project.org/package=tune},
	author = {Kuhn, Max},
	year = {2024},
}

@inproceedings{singla_comprehensive_2023,
	title = {A {Comprehensive} {Study} and {Analysis} {Of} {Frequent} {Itemsets} {Mining} {Algorithms} {Using} {Diverse} {Real} {Datasets}},
	doi = {10.1109/ICAICCIT60255.2023.10466004},
	booktitle = {2023 {International} {Conference} on {Advances} in {Computation}, {Communication} and {Information} {Technology} ({ICAICCIT})},
	author = {Singla, Anshu and Gandhi, Parul},
	year = {2023},
	keywords = {Data mining, Itemsets, Apriori, Clustering algorithms, Computer bugs, Databases, Eclat, FP-Max, Frequent pattern mining (FPM), Frequent patterns, itemset, Relim, SaM, Sensitivity, Software, Software algorithms, support},
	pages = {174--180},
}

@book{kuhn_dials_2024,
	title = {dials: {Tools} for {Creating} {Tuning} {Parameter} {Values}},
	url = {https://CRAN.R-project.org/package=dials},
	author = {Kuhn, Max and Frick, Hannah},
	year = {2024},
}

@book{kuhn_yardstick_2024,
	title = {yardstick: {Tidy} {Characterizations} of {Model} {Performance}},
	url = {https://CRAN.R-project.org/package=yardstick},
	author = {Kuhn, Max and Vaughan, Davis and Hvitfeldt, Emil},
	year = {2024},
}

@article{saito_precision-recall_2015,
	title = {The {Precision}-{Recall} {Plot} {Is} {More} {Informative} than the {ROC} {Plot} {When} {Evaluating} {Binary} {Classifiers} on {Imbalanced} {Datasets}},
	volume = {10},
	url = {https://doi.org/10.1371/journal.pone.0118432},
	doi = {10.1371/journal.pone.0118432},
	abstract = {Binary classifiers are routinely evaluated with performance measures such as sensitivity and specificity, and performance is frequently illustrated with Receiver Operating Characteristics (ROC) plots. Alternative measures such as positive predictive value (PPV) and the associated Precision/Recall (PRC) plots are used less frequently. Many bioinformatics studies develop and evaluate classifiers that are to be applied to strongly imbalanced datasets in which the number of negatives outweighs the number of positives significantly. While ROC plots are visually appealing and provide an overview of a classifier's performance across a wide range of specificities, one can ask whether ROC plots could be misleading when applied in imbalanced classification scenarios. We show here that the visual interpretability of ROC plots in the context of imbalanced datasets can be deceptive with respect to conclusions about the reliability of classification performance, owing to an intuitive but wrong interpretation of specificity. PRC plots, on the other hand, can provide the viewer with an accurate prediction of future classification performance due to the fact that they evaluate the fraction of true positives among positive predictions. Our findings have potential implications for the interpretation of a large number of studies that use ROC plots on imbalanced datasets.},
	number = {3},
	journal = {PLOS ONE},
	author = {Saito, Takaya and Rehmsmeier, Marc},
	month = mar,
	year = {2015},
	note = {Publisher: Public Library of Science},
	pages = {1--21},
}

@inproceedings{dahbi_finding_2021,
	address = {Singapore},
	title = {Finding {Suitable} {Threshold} for {Support} in {Apriori} {Algorithm} {Using} {Statistical} {Measures}},
	isbn = {978-981-336-129-4},
	abstract = {Data mining is one of the noticeable researches. Data mining is one of the most outstanding areas of research, striving to extract meaningful information and useful models from databases and to help managers to make better decisions. Mining association rules is a persistent and popular data mining process. It aims to find frequent models, association correlations, or causal structures between a set of objects in large transactional or relational databases and other data repositories. This paper provides an improvement of the Apriori algorithm, a classic rule extraction algorithm by finding appropriate minimum threshold values for the support automatically using different statistical measures depending on each dataset. The experiments on baseline datasets show a comparative analysis between different proposed methods of generation association rules using the automatic minimum support threshold.},
	booktitle = {Enabling {Machine} {Learning} {Applications} in {Data} {Science}},
	publisher = {Springer Singapore},
	author = {Dahbi, Azzeddine and Jabri, Siham and Balouki, Youssef and Gadi, Taoufiq},
	editor = {Hassanien, Aboul Ella and Darwish, Ashraf and Abd El-Kader, Sherine M. and Alboaneen, Dabiah Ahmed},
	year = {2021},
	pages = {89--101},
}
